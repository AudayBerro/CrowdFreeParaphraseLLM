# About
Contains datasets and code for the paper "LLMs to Replace Crowdsourcing in Generating Syntactically Diverse Paraphrases for Task-Oriented Chatbots".

ðŸ“¤ ðŸš€ Submitted to [CAiSE'25]https://conferences.big.tuwien.ac.at/caise2025/)

## Table of Contents
- [Compare Syntax Template Folder](#compare-syntax-template-folder)
- [Checkpoints Folder](#checkpoints-folder)
- [Input Folder](#input-folder)
- [Lib Folder](#lib-folder)
- [Output Folder](#output-folder)
- [Pilot Folder](#pilot-folder)
- [Plots Folder](#plot-folder)
- [Possible use cases](#possible-use-cases)

# Compare Syntax Template Folder
This file contain script to count syntax templates that appeared in GPT-t/P-12 but absent in Crowd-T/P.  And count number of syntax templates in Crowd-T/P but not in GPT-T/P-12.

# Checkpoints Folder
The `Checkpoints` folder contains CSV files generated as the output of running various configurations described in Section `4.1` of the paper. These configurations correspond to different experimental setups, each producing a set of paraphrases under specific conditions. Below are examples of the CSV files and their corresponding configurations:

- **`pattern_by_example_8-raw-round3.csv`**: This file corresponds to generating paraphrases using the "Pattern_by_example" prompt, where GPT was requested to generate 8 paraphrases per request. In this case, 3 requests were sent per seed utterance to collect a total of 24 paraphrases (8 paraphrases per request). The "raw" token in the file name indicates that no quality evaluation was applied to the paraphrases, such as removing duplicates or semantically unrelated paraphrases, so all generated paraphrases are included.
  
- **`taboo_patterns_12-raw-round2.csv`**: This file corresponds to generating paraphrases using the "Taboo Patterns" prompt, with a request to generate 12 paraphrases per request. To collect a total of 24 paraphrases, 2 requests were sent per seed utterance. As with the previous example, the "raw" token indicates that no quality filtering was applied to the collected paraphrases.

The token **"roundX"** in each file name indicates the request round number. For instance, **round3** means the paraphrases in the file were generated by the third request for the current seed. Since a total of 24 paraphrases are required, and the prompt was set to generate 8 paraphrases per request, **round1** corresponds to the first request, **round2** to the second, and **round3** to the third request.

These CSV files serve as raw outputs that can be further analyzed or processed for quality evaluation, such as removing duplicate or irrelevant paraphrases.

# Input Folder  

The "Input Folder" contains essential files and datasets used as input for the analysis and experiments. Below is a detailed description of its contents:  

1. **PSA.csv**  
   This CSV file includes the following columns:  
   - **`input_utterance`**: The seed utterance in plain text (e.g., *Search for cooking videos*).  
   - **`intent`**: The intent associated with the utterance (e.g., *EndEC2Instance*, *SearchWeb*, *CheckDevice*, *FindHotel*, *BookRestaurant*, *GetWeather*, etc.).  
   - **`parameters`**: Slots and their corresponding values in the utterance (e.g., for the previous utterance, the slot `query` has the value *cooking videos*).  
   - **`parse_template`**: The syntactic structure of the utterance (e.g., *(ROOT (S (VP)))*).  
   - **`source`**: The origin of the seed utterance (e.g., *ParaQuality*, *SNIPS*, *ATIS*).  
   - **`row_pk`**: A unique identifier for each utterance.  

   This file contains 51 seed utterances used in the crowdsourcing study by Jorge et al.  

2. **Jorge-bootstrap-with-bertscores.csv**  
   This CSV file lists paraphrases generated during the Bootstrap round by Jorge et al. Each paraphrase is paired with its BERTScore, measuring semantic similarity between the paraphrase and the seed utterance.  

3. **Pilot Folder**  
   This folder contains datasets and resources used in pilot experiments. These datasets guided the development and refinement of the experiment's final scripts and evaluation code. 

# Lib Folder 

The **Lib Folder** contains various utility scripts that support the functionality of the notebooks used in this study. These scripts provide modular, reusable code for building prompts, processing data, and computing metrics. Below is a description of each script:  

1. **`prompts_utility.py`**  
   This script is responsible for constructing the prompts used in the study and described in the paper. These include:  
   - Baseline prompts  
   - Patterns_by_examples prompts  
   - Taboo_patterns prompts  

2. **`syntax_tree_utility.py`**  
   This module calculates the Tree Edit Distance (TED) between constituency parse trees. The implementation is inspired by [Chen et al.](https://aclanthology.org/P19-1599/). It provides tools for syntactic comparison and syntax tree-based analyses.  

3. **`gpt_utility.py`**  
   This script includes utility functions for interacting with the OpenAI API. It simplifies various tasks related to API interactions, such as request handling and response processing, enhancing usability and manageability.  

4. **`metrics.py`**  
   This module provides metrics relevant to paraphrasing, such as:  
   - Type-Token Ratio (TTR)  
   - PINC (Paraphrase IN N-gram Changes)  
   - BLEU (Bilingual Evaluation Understudy)  

5. **`utility.py`**  
   A general-purpose utility script containing various helper and wrapper functions to process data efficiently and avoid code redundancy.  

   **Purpose:**  
   - **Avoid Redundancy**: Encapsulates reusable code blocks, enabling cleaner implementation of data processing tasks.  
   - **Data Processing**: Handles tasks such as parsing, filtering, transformation, and other operations.  
   - **Improved Readability**: Centralizing utility functions promotes code organization and enhances the readability of other scripts that utilize these functions.  

These scripts form the backbone of the study's computational workflows, enabling efficient and systematic analysis.

# Output Folder  

The **Output Folder** contains datasets generated from various configurations of the experiments. These datasets are organized into seven subfolders, each representing a specific configuration. Below is a detailed description of the subfolders:  

1. **`bootstrap_round/`**  
   Contains paraphrases generated during the bootstrap round. These paraphrases serve as the starting utterance used in subsequent round of the workflow.  

2. **`pattern_by_example/`**  
   Includes paraphrases generated using the *pattern_by_example* prompt with **3 paraphrases per request**.  

3. **`pattern_by_example_8/`**  
   Contains datasets generated using the *pattern_by_example* prompt with **8 paraphrases per request**.  

4. **`pattern_by_example_12/`**  
   Stores datasets generated using the *pattern_by_example* prompt with **12 paraphrases per request**.  

5. **`taboo_patterns/`**  
   Includes paraphrases generated using the *taboo_patterns* prompt with **3 paraphrases per request**.  

6. **`taboo_patterns_8/`**  
   Contains datasets generated using the *taboo_patterns* prompt with **8 paraphrases per request**.  

7. **`taboo_patterns_12/`**  
   Stores datasets generated using the *taboo_patterns* prompt with **12 paraphrases per request**.  

### **Pilot Subfolder**  
The `pilot/` subfolder contains scripts and data used during the pilot phase of the study. These resources helped refine and finalize the experimental setup and methodology.

Each dataset in this folder reflects the configuration used to generate it, providing a systematic structure for analysis and reproducibility.


# Pilot Folder
The **Pilot Folder** contains various scripts and resources used during the preliminary phase of the study. These pilot scripts were instrumental in refining the final version of the experiment. Key functionalities include:  

- Extracting seed utterances and syntax templates.  
- Computing evaluation metrics such as BERTScore, Tree Edit Distance (TED), syntax novelty, and others.  
- Testing and exploring different approaches and configurations before finalizing the experimental setup.  

This folder showcases the iterative development process and the exploratory steps taken to optimize the experiment.  


## Plots folder

This folder contains a collection of graphs and plots generated by the various configuration notebooks. These visualizations provide insights into the performance and diversity of the paraphrasing models used in the study. These visualizations include:  

- **Mean BERTScore Distribution**: Illustrating the distribution of mean BERTScores across different configurations.  
- **Syntax Template Distribution**: Showcasing the frequency and variety of syntax templates generated under each configuration.


## Possible use cases
- Automatic Paraphrasing errors Detection
- Paraphrase Generation
- Training data for Chatbots
- Entity recognition
- Intent classification
- NLU training

## ðŸ“ƒ License
For more information see [LICENSE](https://github.com/AudayBerro/CrowdFreeParaphraseLLM/blob/main/LICENSE).


## More information
ðŸ“« You can contact me via audayberro (at) gmail.com

For more information please refer to our paper. Please also cite the following paper if you are using the dataset in your research:

```sh
@inproceedings{berro-etal-2024-error,
    title = "LLMs to Replace Crowdsourcing in Generating Syntactically Diverse Paraphrases for Task-Oriented Chatbots",
    author = "Berro, Auday  and
      dos Santos, Vitor and
      Benatallah, Boualem  and
      Benabdeslem, Khalid",
    booktitle = "Submitted to CAiSE'25 - International Conferences on Advanced Information Systems Engineering",
    month = June,
    year = "2025",
    address = "Vienna, Austria",
}
```

[snips]: <https://github.com/snipsco/snips-nlu>
